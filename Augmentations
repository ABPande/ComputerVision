import albumentations as A
from albumentations.pytorch import ToTensorV2
import tensorflow as tf
import numpy as np
import cv2
import random

class Augmenter:
    def __init__(self, task="classification", domain="general"):
        """
        Initializes the augmentation pipeline based on the task and domain.

        Parameters:
        - task: "classification", "detection", or "segmentation".
        - domain: "general", "medical", or "satellite".
        """
        self.task = task
        self.domain = domain
        self.augmentations = self._get_augmentations()

    def _get_augmentations(self):
        """
        Returns appropriate augmentations based on the domain.
        """
        general_aug = [
            A.HorizontalFlip(p=0.5),
            A.RandomBrightnessContrast(p=0.2),
            A.Rotate(limit=20, p=0.5),
            A.Cutout(num_holes=8, max_h_size=8, max_w_size=8, p=0.5),
            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
            ToTensorV2()
        ]

        medical_aug = [
            A.HorizontalFlip(p=0.5),
            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),
            A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),
            A.Normalize(mean=(0.485,), std=(0.229,)),  # Grayscale normalization
            ToTensorV2()
        ]

        satellite_aug = [
            A.RandomSizedCrop(min_max_height=(50, 101), height=128, width=128, p=0.5),
            A.HorizontalFlip(p=0.5),
            A.RandomBrightnessContrast(p=0.2),
            A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5),
            A.Normalize(mean=(0.4, 0.4, 0.4), std=(0.2, 0.2, 0.2)),
            ToTensorV2()
        ]

        augmentations = {
            "general": general_aug,
            "medical": medical_aug,
            "satellite": satellite_aug
        }

        bbox_params = A.BboxParams(format="pascal_voc", label_fields=["class_labels"]) if self.task == "detection" else None
        return A.Compose(augmentations[self.domain], bbox_params=bbox_params)

    def apply_augmentation(self, image, label=None, bbox=None, mask=None):
        """
        Applies augmentation to an image and ensures labels are transformed correctly.

        Parameters:
        - image: Input image as a NumPy array.
        - label: Classification label (if applicable).
        - bbox: Bounding box (if object detection).
        - mask: Segmentation mask (if applicable).

        Returns:
        - Transformed image and corresponding label, bbox, or mask.
        """
        if self.task == "classification":
            augmented = self.augmentations(image=image)
            return augmented["image"], label  # Labels remain unchanged in classification

        elif self.task == "detection":
            if bbox is None or label is None:
                raise ValueError("Bounding boxes and labels must be provided for object detection tasks.")
            augmented = self.augmentations(image=image, bboxes=bbox, class_labels=label)
            return augmented["image"], augmented["class_labels"], augmented["bboxes"]

        elif self.task == "segmentation":
            if mask is None:
                raise ValueError("Mask must be provided for segmentation tasks.")
            augmented = self.augmentations(image=image, mask=mask)
            return augmented["image"], mask

    def augment_dataset(self, images, labels=None, bboxes=None, masks=None):
        """
        Applies augmentations to an entire dataset.

        Parameters:
        - images: List/Array of images.
        - labels: List of classification labels.
        - bboxes: List of bounding boxes (if applicable).
        - masks: List of segmentation masks (if applicable).

        Returns:
        - Augmented images, labels, bounding boxes, and masks.
        """
        augmented_images, augmented_labels, augmented_bboxes, augmented_masks = [], [], [], []

        for i in range(len(images)):
            if self.task == "classification":
                transformed_image, transformed_label = self.apply_augmentation(images[i], labels[i])
                augmented_images.append(transformed_image)
                augmented_labels.append(transformed_label)

            elif self.task == "detection":
                transformed_image, transformed_label, transformed_bbox = self.apply_augmentation(images[i], labels[i], bboxes[i])
                augmented_images.append(transformed_image)
                augmented_labels.append(transformed_label)
                augmented_bboxes.append(transformed_bbox)

            elif self.task == "segmentation":
                transformed_image, transformed_mask = self.apply_augmentation(images[i], mask=masks[i])
                augmented_images.append(transformed_image)
                augmented_masks.append(transformed_mask)

        return np.array(augmented_images), np.array(augmented_labels) if augmented_labels else None, augmented_bboxes if augmented_bboxes else None, augmented_masks if augmented_masks else None

    def mixup(self, image1, image2, label1, label2, alpha=0.2):
        """
        Applies MixUp augmentation.

        Parameters:
        - image1, image2: Two images to blend.
        - label1, label2: Corresponding labels.
        - alpha: Beta distribution parameter.

        Returns:
        - Mixed image and label.
        """
        lam = np.random.beta(alpha, alpha)
        mixed_image = lam * image1 + (1 - lam) * image2
        mixed_label = lam * label1 + (1 - lam) * label2
        return mixed_image, mixed_label

    def cutmix(self, image1, image2, label1, label2):
        """
        Applies CutMix augmentation.

        Parameters:
        - image1, image2: Two images to blend.
        - label1, label2: Corresponding labels.

        Returns:
        - CutMix applied image and label.
        """
        h, w, _ = image1.shape
        cx, cy = np.random.randint(w), np.random.randint(h)
        cut_w, cut_h = w // 2, h // 2
        x1, x2 = max(cx - cut_w // 2, 0), min(cx + cut_w // 2, w)
        y1, y2 = max(cy - cut_h // 2, 0), min(cy + cut_h // 2, h)

        image1[y1:y2, x1:x2] = image2[y1:y2, x1:x2]
        lam = (x2 - x1) * (y2 - y1) / (h * w)
        mixed_label = lam * label1 + (1 - lam) * label2

        return image1, mixed_label


# Example Usage
if __name__ == "__main__":
    from tensorflow.keras.datasets import cifar10
    import matplotlib.pyplot as plt

    (train_images, train_labels), _ = cifar10.load_data()
    train_images = np.array([cv2.cvtColor(img, cv2.COLOR_RGB2BGR) for img in train_images])

    augmenter = Augmenter(task="classification", domain="general")
    augmented_images, augmented_labels, _, _ = augmenter.augment_dataset(train_images, train_labels)

    idx = random.randint(0, len(train_images) - 1)

    fig, ax = plt.subplots(1, 2, figsize=(8, 4))
    ax[0].imshow(cv2.cvtColor(train_images[idx], cv2.COLOR_BGR2RGB))
    ax[0].set_title("Original Image")
    ax[0].axis("off")

    ax[1].imshow(augmented_images[idx].transpose(1, 2, 0))
    ax[1].set_title("Augmented Image")
    ax[1].axis("off")

    plt.show()
