import tensorflow as tf
from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import RandomizedSearchCV

def hyperparameter_tuning(model_fn, train_images, train_labels, param_grid=None, n_iter=10):
    """
    Performs hyperparameter tuning using RandomizedSearchCV.
    
    Parameters:
    - model_fn: Function that returns a compiled Keras model.
    - train_images: NumPy array of training images.
    - train_labels: NumPy array of training labels.
    - param_grid: Dictionary of hyperparameters to tune.
    - n_iter: Number of iterations for RandomizedSearchCV.
    
    Returns:
    - Best model found.
    - Best hyperparameters.
    """
    if param_grid is None:
        param_grid = {
            'learning_rate': [0.001, 0.0001, 0.01],
            'dropout_rate': [0.2, 0.3, 0.4],
            'num_filters': [32, 64, 128],
            'kernel_size': [3, 5]
        }
    
    model = KerasClassifier(build_fn=model_fn, verbose=0)
    random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=n_iter, cv=3, verbose=1, n_jobs=-1)
    random_search.fit(train_images, train_labels)
    
    return random_search.best_estimator_, random_search.best_params_

# Example usage
if __name__ == "__main__":
    from tensorflow.keras.datasets import cifar10
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

    def build_model(learning_rate=0.001, dropout_rate=0.3, num_filters=32, kernel_size=3):
        model = Sequential([
            Conv2D(num_filters, (kernel_size, kernel_size), activation='relu', input_shape=(32, 32, 3)),
            MaxPooling2D(pool_size=(2, 2)),
            Flatten(),
            Dense(128, activation='relu'),
            Dropout(dropout_rate),
            Dense(10, activation='softmax')
        ])
        
        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)
        model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
        
        return model
    
    (train_images, train_labels), (_, _) = cifar10.load_data()
    train_images = train_images / 255.0  # Normalize images
    
    best_model, best_params = hyperparameter_tuning(build_model, train_images, train_labels)
    print("Best Hyperparameters:", best_params)
    best_model.model.summary()
